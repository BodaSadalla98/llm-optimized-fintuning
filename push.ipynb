{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel    \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters_name  = \"experiments/Llama-2-7b-hf/checkpoint-24000\"\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4db5510e394c02b24e5857d744a540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto'\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, adapters_name)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "tokenizer.bos_token_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9847b13d5ab34bc984ecbc10f4d44d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/640M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boda/llama2-7b-story-generation-24k/commit/e1e331a60db09908d1db19a96928cf54444c37f6', commit_message='Upload model', commit_description='', oid='e1e331a60db09908d1db19a96928cf54444c37f6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"boda/llama2-7b-story-generation-24k\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f7b40ccf7145578aa8944c88d1517e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boda/llama2-7b-story-generation-24k/commit/1f9e98c562936baf9d11db9b1b61843ad09384fc', commit_message='Upload tokenizer', commit_description='', oid='1f9e98c562936baf9d11db9b1b61843ad09384fc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"boda/llama2-7b-story-generation-24k\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters_name2  = \"experiments/Mistral-7B-v0.1/checkpoint-24000\"\n",
    "model_name2 = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445eb2bbea054a5594db28bf2c104dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name2,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto'\n",
    ")\n",
    "model2 = PeftModel.from_pretrained(model2, adapters_name2)\n",
    "tokenizer2 = LlamaTokenizer.from_pretrained(model_name2)\n",
    "tokenizer2.bos_token_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ced25c3a4224bf5a7e6b4c1ac497ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/671M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boda/mistral-7b-story-generation-24k/commit/4567b6c200c62e8dadc00756befd8a4b13cd81cf', commit_message='Upload model', commit_description='', oid='4567b6c200c62e8dadc00756befd8a4b13cd81cf', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.push_to_hub(\"boda/mistral-7b-story-generation-24k\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8612f0959576488785ac775eed25711f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boda/mistral-7b-story-generation-24k/commit/ca21d8f55fd53ca3b51a8134428821be05b103ff', commit_message='Upload tokenizer', commit_description='', oid='ca21d8f55fd53ca3b51a8134428821be05b103ff', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2.push_to_hub(\"boda/mistral-7b-story-generation-24k\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters_name  = \"experiments/jais/checkpoint-170000\"\n",
    "model_name = \"/home/abdelrahman.sadallah/.cache/huggingface/hub/jais\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapters_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/boda/jais-13b-poem-generation/commit/cc8ebf68ecb9d7efb37c1f4521510dfc852c7f16', commit_message='Upload tokenizer', commit_description='', oid='cc8ebf68ecb9d7efb37c1f4521510dfc852c7f16', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"boda/jais-13b-poem-generation\", token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": " (Request ID: Root=1-65607810-6cc4e9d609a0797e4adeeb57;6c248ee1-04f7-4259-bc4d-911052598e32)\n\nBad request for commit endpoint:\n\"base_model\" with value \"/home/abdelrahman.sadallah/.cache/huggingface/hub/jais\" is not valid. Use a model id from https://hf.co/models.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://huggingface.co/api/models/boda/jais-13b-poem-generation/commit/main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mpush_to_hub(\u001b[39m\"\u001b[39;49m\u001b[39mboda/jais-13b-poem-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m, token\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhf_vHlYsZMckgWriaCBqGbhhFVmhOIAOZuWzY\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/utils/hub.py:905\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[39m# Save all files.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_pretrained(work_dir, max_shard_size\u001b[39m=\u001b[39mmax_shard_size, safe_serialization\u001b[39m=\u001b[39msafe_serialization)\n\u001b[0;32m--> 905\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_modified_files(\n\u001b[1;32m    906\u001b[0m     work_dir,\n\u001b[1;32m    907\u001b[0m     repo_id,\n\u001b[1;32m    908\u001b[0m     files_timestamps,\n\u001b[1;32m    909\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[1;32m    910\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    911\u001b[0m     create_pr\u001b[39m=\u001b[39;49mcreate_pr,\n\u001b[1;32m    912\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    913\u001b[0m     commit_description\u001b[39m=\u001b[39;49mcommit_description,\n\u001b[1;32m    914\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/utils/hub.py:781\u001b[0m, in \u001b[0;36mPushToHubMixin._upload_modified_files\u001b[0;34m(self, working_dir, repo_id, files_timestamps, commit_message, token, create_pr, revision, commit_description)\u001b[0m\n\u001b[1;32m    778\u001b[0m     create_branch(repo_id\u001b[39m=\u001b[39mrepo_id, branch\u001b[39m=\u001b[39mrevision, token\u001b[39m=\u001b[39mtoken, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    780\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploading the following files to \u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(modified_files)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 781\u001b[0m \u001b[39mreturn\u001b[39;00m create_commit(\n\u001b[1;32m    782\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m    783\u001b[0m     operations\u001b[39m=\u001b[39;49moperations,\n\u001b[1;32m    784\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[1;32m    785\u001b[0m     commit_description\u001b[39m=\u001b[39;49mcommit_description,\n\u001b[1;32m    786\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    787\u001b[0m     create_pr\u001b[39m=\u001b[39;49mcreate_pr,\n\u001b[1;32m    788\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    789\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/huggingface_hub/hf_api.py:828\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    827\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2728\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   2726\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2727\u001b[0m     commit_resp \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mpost(url\u001b[39m=\u001b[39mcommit_url, headers\u001b[39m=\u001b[39mheaders, data\u001b[39m=\u001b[39mdata, params\u001b[39m=\u001b[39mparams)\n\u001b[0;32m-> 2728\u001b[0m     hf_raise_for_status(commit_resp, endpoint_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcommit\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2729\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   2730\u001b[0m     e\u001b[39m.\u001b[39mappend_to_message(_CREATE_COMMIT_NO_REPO_ERROR_MESSAGE)\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:299\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[1;32m    296\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    297\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mBad request for \u001b[39m\u001b[39m{\u001b[39;00mendpoint_name\u001b[39m}\u001b[39;00m\u001b[39m endpoint:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m endpoint_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mBad request:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mraise\u001b[39;00m BadRequestError(message, response\u001b[39m=\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39mraise\u001b[39;00m HfHubHTTPError(\u001b[39mstr\u001b[39m(e), response\u001b[39m=\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m:  (Request ID: Root=1-65607810-6cc4e9d609a0797e4adeeb57;6c248ee1-04f7-4259-bc4d-911052598e32)\n\nBad request for commit endpoint:\n\"base_model\" with value \"/home/abdelrahman.sadallah/.cache/huggingface/hub/jais\" is not valid. Use a model id from https://hf.co/models."
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"boda/jais-13b-poem-generation\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
